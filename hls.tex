
\titleformat{\chapter}[hang] 
{\normalfont\huge\bfseries}{\chaptertitlename\ \thechapter:}{1em}{} 

\chapter{Proofs of Theorems}

\section{Proof of The Substitution Theorem}\label{sec:substitution-proof}

\Cref{theorem:substitution} says that
if $Θ;Γ,(x:T_x) ⊢ M : T$ and $Θ;Γ ⊢ V : T_x$,
then $Θ;Γ ⊢ M[x := V] : T$.
We first prove a few lemmas.

\begin{lemma}[Enclave]\label{theorem:enclave}
    If $Θ;Γ ⊢ V : T$ and $Θ' \subseteq Θ$
    and $T' = T \mask Θ'$ is defined
    then $V' = V \mask Θ'$ is defined,
    and $Θ';Γ ⊢ V' : T'$.
\end{lemma}

\subsection{Proof of \Cref{theorem:enclave}}
This is vacuous if $T'$ doesn't exist, so assume it does.
Do induction on the definition of masking for $T$:

\begin{itemize}
\item \textsc{MTData}: $Θ;Γ ⊢ V : d@\nonempty{p}$ and $\nonempty{p} ∩ Θ' ≠ ∅$
  so $T' = d@(\nonempty{p} ∩ Θ')$.
  Consider cases for typing of $V$:
  \begin{itemize}
    \item \textsc{TVar}: $V' = V$ by \textsc{MVVar} and it types by \textsc{TVar} b.c. $T'$ exists.
    \item \textsc{TUnit}: We've already assumed the preconditions for \textsc{MVUnit}, and it types.
    \item \textsc{TPair}: $V = \PAIR V_1 V_2$,
      and $Θ;Γ ⊢ V_1 : d_1@(\nonempty{p_1} \supseteq \nonempty{p})$
      and $Θ;Γ ⊢ V_2 : d_2@(\nonempty{p_2} \supseteq \nonempty{p})$.
      By \textsc{MTData}, these larger-owernership types will still mask with $Θ'$,
      so this case come by induction.
    \item \textsc{TInL}, \textsc{TInR}: Follows by simple induction.
  \end{itemize}
\item \textsc{MTFunction}: $T' = T$ and $\nonempty{p} \subseteq Θ'$,
  so lambdas and function-keywords all project unchanged, and the respective typings hold.
\item \textsc{MTVector}: Simple induction.
\end{itemize}

\begin{lemma}[Quorum]\label{theorem:quorum}
    \textbf{A)} If $Θ;Γ,(x:T_x) ⊢ M : T$ and $T_x' = T_x \mask Θ$, then $Θ;Γ,(x:T_x') ⊢ M : T$.

    \textbf{B)} If $Θ;Γ,(x:T_x) ⊢ M : T$ and $T_x \mask Θ$ is not defined, then $Θ;Γ ⊢ M : T$.
\end{lemma}

\subsection{Proof of \Cref{theorem:quorum}}
By induction on the typing of M.
The only case that's not recursive or trivial is \textsc{TVar},
for which we just need to observe that masking on a given party-set is idempotent.


\begin{lemma}[Unused]\label{theorem:unused}
  If $Θ;Γ ⊢ M : T$ and $x \not \in Γ$, then $M[x := V] = M$.
\end{lemma}
\subsection{Proof of \Cref{theorem:unused}}
By induction on the typing of $M$.
There are no non-trivial cases.

\subsection{\Cref{theorem:substitution}}

\Cref{theorem:substitution} says that
  if $Θ;Γ,(x:T_x) ⊢ M : T$ and $Θ;Γ ⊢ V : T_x$,
  then $Θ;Γ ⊢ M[x := V] : T$.

The proof is in 13 cases.
\textsc{TProjN}, \textsc{TProj1}, \textsc{TProj2}, \textsc{TCom}, and \textsc{TUnit}
are trivial base cases.
\textsc{TInL}, \textsc{TInR}, \textsc{TVec}, and \textsc{TPair}
are trivial recursive cases.

\begin{itemize}
  \item \textsc{TLambda} where $T_x' = T_x \mask \nonempty{p}$:
  $M = (λ y : T_y \DOT N)@\nonempty{p}$ and $T = (T_y → T')@\nonempty{p}$.
  \begin{enumerate}
      \item $Θ;Γ,(x:T_x) ⊢ (λ y : T_y \DOT N)@\nonempty{p} : (T_y → T')@\nonempty{p}$ by assumption.
      \item $Θ;Γ ⊢ V : T_x$ by assumption.
      \item $\nonempty{p};Γ,(x:T_x),(y:T_y) ⊢ N : T'$ per preconditions of \textsc{TLambda}.
      \item $Θ;Γ,(y:T_y) ⊢ V : T_x$ by weakening (or strengthening?) \#2.
      \item $V' = V \mask \nonempty{p}$ and $\nonempty{p}; Γ,(y:T_y) ⊢ V' : T_x'$ by \Cref{theorem:enclave}.
      \item $\nonempty{p};Γ,(x:T_x'),(y:T_y) ⊢ N : T'$ by applying \Cref{theorem:quorum} to \#3.
      \item $\nonempty{p};Γ,(y:T_y) ⊢ N[x:=V'] : T'$ by induction on \#6 and \#5.
      \item $M[x:=V] = (λ y : T_y \DOT N[x:=V'])@\nonempty{p}$ by definition,
     which typechecks by \#7 and \textsc{TLambda}. \textbf{QED.}
  \end{enumerate}
  \item \textsc{TLambda} where $T_x \mask \nonempty{p}$ is undefined:
  $M = (λ y : T_y \DOT N)@\nonempty{p}$.
  \begin{enumerate}
      \item $\nonempty{p};Γ,(x:T_x),(y:T_y) ⊢ N : T'$ per preconditions of \textsc{TLambda}.
      \item $\nonempty{p};Γ,(y:T_y) ⊢ N : T'$ by \Cref{theorem:quorum} B.
      \item $N[x:=V] = N$ by \Cref{theorem:unused},
     so regardless of the existence of $V \mask \nonempty{p}$ the substitution is a noop,
     and it typechecks by \#2 and \textsc{TLambda}.
  \end{enumerate}
  \item \textsc{TVar}: Follows from the relevant definitions, whether $x ≡ y$ or not.
  \item \textsc{TApp}: This is also a simple recursive case;
  the masking of $T_a$ doesn't affect anything.
  \item \textsc{TCase}: Follows the same logic as \textsc{TLambda},
  just duplicated for $M_l$ and $M_r$.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of The Preservation Theorem}\label{sec:preservation-proof}
\Cref{theorem:preservation} says that
if $Θ;∅ ⊢ M : T$ and $M \step M'$,
then $Θ;∅ ⊢ M' : T$.
We'll need a few lemmas first.

\begin{lemma}[Sub-Mask]\label{theorem:sub-mask}
  If $Θ;Γ ⊢ V : d@\nonempty{p}$ and $∅ ≠ \nonempty{q} \subseteq \nonempty{p}$,
    then \textbf{A:} $d@\nonempty{p} \mask \nonempty{q} = d@\nonempty{q}$ is defined
    and \textbf{B:} $V \mask \nonempty{q}$ is also defined and types as $d@\nonempty{q}$.
\end{lemma}
\subsection{Proof of \Cref{theorem:sub-mask}}
Part A is obvious by \textsc{MTData}.
Part B follows by induction on the definition of masking for values.
\begin{itemize}
\item \textsc{MVLambda}: Base case; can't happen because it wouldn't allow a data type.
\item \textsc{MVUnit}: Base case; passes definition and typing.
\item \textsc{MVInL}, \textsc{MVInR}: Recursive cases.
\item \textsc{MVPair}: Recursive case.
\item \textsc{MVVector}: Can't happen because it wouldn't allow a data type.
\item \textsc{MVProj1}, \textsc{MVProj2}, \textsc{MVProjN}, and \textsc{MVCom}:
  Base cases, can't happen because they wouldn't allow a data type.
\item \textsc{MVVar}: Base case, trivial.
\end{itemize}

\begin{lemma}[Maskable]\label{theorem:maskable}
  If $Θ;Γ ⊢ V : T$ and $T \mask \nonempty{p} = T'$,
  then \textbf{A:} $V \mask \nonempty{p} = V'$ is defined
    and \textbf{B:} $Θ;Γ ⊢ V' : T'$.
\end{lemma}
\subsection{Proof of \Cref{theorem:maskable}}
By induction on the definition of masking for values.
\begin{itemize}
\item \textsc{MVLambda}: Base case. From the type-masking assumption, \textsc{MTFunction},
  $\nonempty{p}$ is a superset of the owners,
  so $T' = T$, so $V' = V$.
\item \textsc{MVUnit}: Base case; passes definition and typing.
\item \textsc{MVInL}, \textsc{MVInR}: Recursive cases.
\item \textsc{MVPair}: Recursive case.
\item \textsc{MVVector}: Recursive case.
\item \textsc{MVProj1}, \textsc{MVProj2}, \textsc{MVProjN}, and \textsc{MVCom}:
  From the typing assumption, $\nonempty{p}$ is a superset of the owners,
  so $T' = T$ and $V' = V$.
\item \textsc{MVVar}: Base case, trivial.
\end{itemize}

\begin{lemma}[Exclave]\label{theorem:exclave}
  If $Θ;∅ ⊢ M : T$ and $Θ \subseteq Θ'$
  then $Θ';∅ ⊢ M : T$.
\end{lemma}
\subsection{Proof of \Cref{theorem:exclave}}
By induction on the typing of $M$.
\begin{itemize}
\item \textsc{TLambda}: The recursive typing is unaffected,
  and the other tests are fine with a larger set.
\item \textsc{TVar}: Can't apply with an empty type context.
\item All other cases are unaffected by the larger party-set.
\end{itemize}


\subsection{\Cref{theorem:preservation}}

To repeat: \Cref{theorem:preservation} says that
if $Θ;∅ ⊢ M : T$ and $M \step M'$,
then $Θ;∅ ⊢ M' : T$.

We prove this by induction on typing rules for $M$.
The eleven base cases (values) fail the assumption that $M$ can step,
so we consider the recursive cases:

\begin{itemize}
\item \textsc{TCase}: $M$ is of form $\CASE{\nonempty{p}}{N}{x_l}{M_l}{x_r}{M_r}$.
  There are three ways it might step:
  \begin{itemize}
  \item \textsc{CaseL}: $N$ is of form $\INL V$, $V'$ exists, and $M' = M_l[x_l := V']$.
    \begin{enumerate}
    \item $\nonempty{p};(x_l:d_l@\nonempty{p}) ⊢ M_l : T$ by the preconditions of \textsc{TCase}.
    \item $Θ;∅ ⊢ V : d_l@\nonempty{p}$ because $N$ must type by \textsc{TInL}.
    \item $\nonempty{p};∅ ⊢ V' : d_l@\nonempty{p}$ by \Cref{theorem:enclave} and \textsc{MTData}.
    \item $\nonempty{p};∅ ⊢ M_l[x_l := V'] : T$ by \Cref{theorem:substitution}.
    \item $Θ;∅ ⊢ M_l[x_l := V'] : T$ by \Cref{theorem:exclave}. \textbf{QED.}
    \end{enumerate}
  \item \textsc{CaseR}: Same as \textsc{CaseL}.
  \item \textsc{Case}: $N \step N'$, and by induction and \textsc{TCase},
    $Θ;Γ⊢ N' : T_N$,
    so the original typing judgment will still apply.
  \end{itemize}
\item \textsc{TApp}: $M$ is of form $F A$, and $F$ is of a function type and $A$ also types
  (both in the empty typing context).
  If the step is by \textsc{App2}or \textsc{App1}, then recursion is easy.
  There are eight other ways the step could happen:
  \begin{itemize}
  \item \textsc{AppAbs}: $F$ must type by \textsc{TLambda}.
    $M = ((λ x : T_x \DOT B)@\nonempty{p}) A$.
    We need to show that $A' = A \mask \nonempty{p}$ exists and $Θ;∅ ⊢ B[x := A'] : T$.
    \begin{enumerate}
    \item $\nonempty{p};(x:T_x) ⊢ B : T$ by the preconditions of \textsc{TLambda}.
    \item $Θ;∅ ⊢ A : T_a'$ such that $T_x = T_a' \mask \nonempty{p}$,
       by the preconditions of \textsc{TApp}.
    \item $A'$ exists and $\nonempty{p};∅ ⊢ A' : T_x$ by \Cref{theorem:enclave} on \#2.
    \item $\nonempty{p};∅ ⊢ B[x := A'] : T$ by \Cref{theorem:substitution}.
    \item \textbf{QED.} by \Cref{theorem:exclave}.
    \end{enumerate}
  \item \textsc{Proj1}: $F = \FST{\nonempty{p}}$ and $A = \PAIR V_1 V_2$ and
    $M' = V_1 \mask \nonempty{p}$.
    Necessarily, by \textsc{TPair} $Θ;∅ ⊢ V_1 : d_1@\nonempty{p_1}$
    where $\nonempty{p} \subseteq \nonempty{p_1}$.
    By \Cref{theorem:sub-mask}, $Θ;∅ ⊢ M' : T$.
  \item \textsc{Proj2}: same as \textsc{Proj1}.
  \item \textsc{ProjN}: $F = \LOOKUP{i}{\nonempty{p}}$ and $A = (\dots, V_i, \dots)$
    and $M' = V_i \mask \nonempty{p}$.
    Necessarily, by \textsc{TVec} $Θ;∅ ⊢ V_i : T_i$ and $Θ;∅ ⊢ A : (\dots, T_i, \dots)$.
    By \textsc{TApp}, $(\dots, T_i, \dots) \mask \nonempty{p} = T_a$,
    so by \textsc{MTVector} $T_i \mask \nonempty{p}$ exists
    and (again by \textsc{TApp} and \textsc{TProjN}) it must equal $T$.
    \textbf{QED.} by \Cref{theorem:maskable}.
  \item \textsc{Com1}: By \textsc{TCom} and \textsc{TUnit}.
  \item \textsc{ComPair}: Recusion among the \textsc{Com*} cases.
  \item \textsc{ComInl}:  Recusion among the \textsc{Com*} cases.
  \item \textsc{ComInr}:  Recusion among the \textsc{Com*} cases.
  \end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of The Progress Theorem}\label{sec:progress-proof}

\Cref{theorem:progress} says that
if $Θ;∅ ⊢ M : T$,
then either M is of form $V$ (which cannot step)
or their exists $M'$ s.t. $M \step M'$.

The proof is by induction of typing rules.
There are eleven base cases and two recursive cases.
Base cases:
\begin{itemize}
\item \textsc{TLambda}
\item \textsc{TVar} (can't happen, by assumption)
\item \textsc{TUnit}
\item \textsc{TCom}
\item \textsc{TPair}
\item \textsc{TVec}
\item \textsc{TProj1}
\item \textsc{TProj2}
\item \textsc{TProjN}
\item \textsc{TInl}
\item \textsc{TInr}
\end{itemize}

Recursive cases:
\begin{itemize}
\item \textsc{TCase}: $M$ is of form $\CASE{\nonempty{p}}{N}{x_l}{M_l}{x_r}{M_r}$
  and ${Θ;∅ ⊢ N : (d_l + d_r)@\nonempty{p}}$.
  By induction, either $N$ can step, in which case M can step by \textsc{Case},
  or $N$ is a value.
  The only typing rules that would give an $N$ of form $V$ the required type are
  \textsc{TVar} (which isn't compatible with the assumed empty $Γ$),
  and \textsc{TInl} and \textsc{TInr}, which respectively force $N$ to have the required forms
  for $M$ to step by \textsc{CaseL} or \textsc{CaseR}.
  From the typing rules, \textsc{MTData}, and the first part of \Cref{theorem:enclave},
  the masking required by the step rules is possible.
\item \textsc{TApp}: $M$ is of form $F A$, and $F$ is of a function type and $A$ also types
  (both in the same empty $Γ$).
  By induction, either $F$ can step (so $M$ can step by \textsc{App2}),
  or $A$ can step (so $M$ can step by \textsc{App1}),
  or $F$ and $A$ are both values.
  Ignoring the impossible \textsc{TVar} cases,
  there are five ways an $F$ of form $V$ could type as a function;
  in each case we get to make some assumption about the type of $A$.
  Furthermore, by \textsc{TApp} and \Cref{theorem:enclave},
  we know that $A$ can mask to the owners of $F$.
  \begin{itemize}
  \item \textsc{TProj1}: $A$ must be a value of type $(d_1×d_2)@\nonempty{q}$,
    and must type by \textsc{TPair}, so it must have form $\PAIR V_1 V_2$,
    so $M$ must step by \textsc{Proj1}.
    We know $V_1$ can mask by \textsc{MVPair}.
  \item \textsc{TProj2}: (same as \textsc{TProj1})
  \item \textsc{TProjN}: $A$ must be a value of type $(T_1,\dots,T_n)$ with $i ≤ n$
    and must type by \textsc{TVec}, so it must have from $(V_1,\dots,V_n)$.
    $M$ must step by \textsc{ProjN}.
    We known $V_i$ can step by \textsc{MVVector}.
  \item \textsc{TCom}: $A$ must be a value of type $d@\nonempty{q}$,
      such that $d@\nonempty{q} \mask \nonempty{s} = d@\nonempty{s}$.
          For that to be true, \textsc{MTData} requires that $\nonempty{s} \subseteq \nonempty{q}$.
    $A$ can type that way under \textsc{TUnit}, \textsc{TPair}, \textsc{TInl}, or \textsc{TInr},
    which respectively force forms $()@\nonempty{q}$, $\PAIR V_1 V_2$, $\INL V$, and $\INR V$,
    which respectively require that $M$ reduce by
    \textsc{Com1}, \textsc{ComPair}, \textsc{ComInl}, and \textsc{ComInr}.
          In the case of $()$, this follows from \Cref{theorem:sub-mask},
          since $\set{s} \subseteq \nonempty{s} \subseteq \nonempty{q}$;
    the other three are recursive among each other.
  \item \textsc{TLambda}: $M$ must reduce by \textsc{AppAbs}.
      By the assumption of \textsc{TApp} and \Cref{theorem:maskable}, it can.
  \end{itemize}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of The Soundness Theorem}\label{sec:soundness-proof}
\Cref{theorem:soundness} says that
if $Θ;∅ ⊢ M : T$ and $⟦M⟧ \netstep{}{∅}^{\ast} \mathcal{N}_n$,
then there exists $M'$ such that
$M \step^{\ast} M'$ and $\mathcal{N}_n \netstep{}{∅}^{\ast} ⟦M'⟧$.
We'll need a few lemmas first.

\begin{lemma}[Values]\label{theorem:values}
  \textbf{A):} $⟦V⟧_p = L$.
  \textbf{B):} If $⟦M⟧_p = L \neq ⊥$ then $M$ is a value $V$.

  Proof is by inspection of the definition of projection.
\end{lemma}
\begin{corollary}\label{theorem:values-cor}
  If $N$ is well-typed and $⟦N⟧$ can step at all,
    then \textbf{(A)} $N$ can step to some $N'$
    and \textbf{(B)} $⟦N⟧$ can multi-step to $⟦N'⟧$ with empty annotation.

    \textbf{A} follows from \Cref{theorem:values} and \Cref{theorem:progress}.
    \textbf{B} is just \Cref{theorem:completeness}.
\end{corollary}

\begin{lemma}[Determinism]\label{theorem:determinism}
  If
  $\mathcal{N}_a \mid \mathcal{N}_0 \netstep{}{∅} \mathcal{N}_a \mid \mathcal{N}_1$
  s.t. for every $p[B_0] \in \mathcal{N}_0$, $\mathcal{N}_1(p) \neq B_0$, \\
    \emph{and}
  $\mathcal{N}_b \mid \mathcal{N}_0 \netstep{}{∅} \mathcal{N}_c \mid \mathcal{N}_2$
  s.t. the domain of $\mathcal{N}_2$ equals the domain of $\mathcal{N}_0$,  
    then \emph{either}
    \begin{itemize}
        \item $\mathcal{N}_2 = \mathcal{N}_0$, \emph{or}
        \item $\mathcal{N}_2 = \mathcal{N}_1$ and $\mathcal{N}_b = \mathcal{N}_c$.
    \end{itemize}
\end{lemma}

\subsection{Proof of \Cref{theorem:determinism}} First, observe that for every non-value expression in the process language,
there is at most one rule in the process semantics by which it can step.
(For values, there are zero.)
Furthermore, the only way for
the step annotation and resulting expression to \emph{not} be fully determined
by the initial expression
is if the justification is based on a \textsc{LRecv} step,
in which case the send-annotation will be empty
and the resulting expression will match the (single) item in the receive-annotation.

$\mathcal{N}_a \mid \mathcal{N}_0 \netstep{}{∅} \mathcal{N}_a \mid \mathcal{N}_1$
must happen by \textsc{NPar}, so consider the $\mathcal{N}_0$ step that enables it;
call that step \stepname{S}.
\stepname{S} can't be by \textsc{NPar};
that would imply parties in $\mathcal{N}_0$ who don't step.
\begin{itemize}
    \item If \stepname{S} is by \textsc{NPro}, then $\mathcal{N}_0 = p[B_0]$ is a singleton
  and \stepname{S} is justified by a process step with empty annotation.
  As noted above, that process step is the only step $B_0$ can take,
  so the
  $\mathcal{N}_b \mid \mathcal{N}_0 \netstep{}{∅} \mathcal{N}_c \mid \mathcal{N}_2$
  step must either be a \textsc{NPar} composing some other party(ies) step
  with $\mathcal{N}_0$ (satisfying the first choice),
  or a \textsc{NPar} composing \stepname{S} with $\mathcal{N}_b$
  (satisfying the second).
\item If \stepname{S} is by \textsc{NCom}, then there must be both
  a singleton \textsc{NPro} step justified by a process step
  (by some party $s$)
  with nonempty send-annotation
  and a nonempty sequence of other party steps
  (covering the rest of $\mathcal{N}_0$'s domain)
  that it gets matched with
  each with a corresponding receive-annotation.
  The send-annotated \textsc{NPro} step is deterministic in the same way as
  an empty-annotated \textsc{NPro} step.
  In order for the parties to cancel out, it can only compose by \textsc{NCom}
  with (a permutation of) the same sequence of peers.
  Considered in isolation, the peers are non-deterministic,
  but their process-steps can only be used in the network semantics by composing
  with $s$ via \textsc{NCom},
  and their resulting expressions are determined by the matched process annotation,
  which is determined by $s$'s step. \\
  Thus, for any $p[B_2] \in \mathcal{N}_2$,
  $B_2 \neq \mathcal{N}_0(p)$ implies that
  for all $q[B_2'] \in \mathcal{N}_2$, $B_2' = \mathcal{N}_1(p)$.
  In the case where $\mathcal{N}_2 = \mathcal{N}_1$,
  the step from $\mathcal{N}_0$ could only have composed with
  $\mathcal{N}_b$ by \textsc{NPar},
  so $\mathcal{N}_b = \mathcal{N}_c$, Q.E.D.
\end{itemize}

\begin{lemma}[Parallelism]\label{theorem:parallelism}
  \textbf{A):} If $\mathcal{N}_1 \netstep{}{∅}^{\ast} \mathcal{N}_1'$
  and $\mathcal{N}_2 \netstep{}{∅}^{\ast} \mathcal{N}_2'$
  then $\mathcal{N}_1 \mid \mathcal{N}_2 \netstep{}{∅}^{\ast}
  \mathcal{N}_1' \mid \mathcal{N}_2 \netstep{}{∅}^{\ast}
  \mathcal{N}_1' \mid \mathcal{N}_2'$. \\
  \textbf{B):} If $\mathcal{N}_1 \mid \mathcal{N}_2 \netstep{}{∅}^{\ast}
  \mathcal{N}_1' \mid \mathcal{N}_2 \netstep{}{∅}^{\ast}
  \mathcal{N}_1' \mid \mathcal{N}_2'$,
  then $\mathcal{N}_1 \netstep{}{∅}^{\ast} \mathcal{N}_1'$
  and $\mathcal{N}_2 \netstep{}{∅}^{\ast} \mathcal{N}_2'$.
\end{lemma}

\subsection{Proof of \Cref{theorem:parallelism}}
\textbf{A} is just repeated application of \textsc{NPar}. \\
For \textbf{B}, observer that in the derivation tree of ever step of the sequence, some (possibly different)
minimal sub-network will step by \textsc{NPro} or {NCom} as a precondition
to some number of layers of \textsc{NPar}.
The domains of these minimal sub-networks will be subsets of the domains of $\mathcal{N}_1$
and $\mathcal{N}_2$ respectively,
so they can just combine via \textsc{NPar} to get the needed step in the respective sequences for
$\mathcal{N}_1$ and $\mathcal{N}_2$.

\subsection{\Cref{theorem:soundness}}
\Cref{theorem:soundness} says that
  if $Θ;∅ ⊢ M : T$ and $⟦M⟧ \netstep{}{∅}^{\ast} \mathcal{N}_n$,
  then there exists $M'$ such that
  $M \step^{\ast} M'$ and $\mathcal{N}_n \netstep{}{∅}^{\ast} ⟦M'⟧$.

Declare the predicate $\mathsf{sound}(\mathcal{N})$ to mean that
there exists some $M_{\mathcal{N}}$ such that
$M \step^{\ast} M_{\mathcal{N}}$
and $\mathcal{N} \netstep{}{∅}^{\ast} ⟦M_{\mathcal{N}}⟧$.

Consider the sequence of network steps
$⟦M⟧ = \mathcal{N}_0 \netstep{}{∅} \dots \netstep{}{∅} \mathcal{N}_n$.
By \Cref{theorem:values-cor}, $\mathsf{sound}(\mathcal{N}_0)$.
Select the largest $i$ s.t. $\mathsf{sound}(\mathcal{N}_i)$.
We will derive a contradiction from an assumption that
$\mathcal{N}_{i+1}$ is part of the sequence;
this will prove that $i=n$, which completes the proof of the Theorem.

Choose a sequence of network steps (of the possibly many such options)
$\mathcal{N}_i = \mathcal{N}^a_i \netstep{}{∅} \dots \netstep{}{∅}
\mathcal{N}^a_m = ⟦M^a⟧$
where $M \step^{\ast} M^a$.

Assume $\mathcal{N}_{i+1}$ is part of the original sequence.
Decompose the step to it as
$\mathcal{N}_i = \mathcal{N}^0_i \mid \mathcal{N}^1_i \netstep{}{∅}
\mathcal{N}^0_i \mid \mathcal{N}^1_{i+1} = \mathcal{N}_{i+1}$
where $\mathcal{N}^1_i$'s domain is as large as possible.
We will examine two cases:
either the parties in $\mathcal{N}^1_i$ make steps in the sequence to
$\mathcal{N}^a_m$, or they do not.
Specifically, consider the largest $j$ s.t.
$\mathcal{N}^a_j = \mathcal{N}^b_j \mid \mathcal{N}^1_i$.

\begin{itemize}
\item Suppose $j < m$. \\
  By \Cref{theorem:determinism} and our decision that $j$ is as large as possible,
  $\mathcal{N}^a_{j+1} = \mathcal{N}^b_j \mid \mathcal{N}^1_{i+1}$.
  Thus we have
  $\mathcal{N}^0_i \mid \mathcal{N}^1_i \netstep{}{∅}^{\ast}
   \mathcal{N}^b_j \mid \mathcal{N}^1_i \netstep{}{∅}
   \mathcal{N}^b_j \mid \mathcal{N}^1_{i+1}$.
  By \Cref{theorem:parallelism}, we can reorganize that into an alternative sequence where
  $\mathcal{N}^0_i \mid \mathcal{N}^1_i \netstep{}{∅}
   \mathcal{N}^0_i \mid \mathcal{N}^1_{i+1} \netstep{}{∅}^{\ast}
   \mathcal{N}^b_j \mid \mathcal{N}^1_{i+1}$.
  Since $\mathcal{N}^0_i \mid \mathcal{N}^1_{i+1} = \mathcal{N}_{i+1}$
  and $\mathcal{N}^a_{j+1} \netstep{}{∅}^{\ast} ⟦M^a⟧$,
  this contradicts our choice that $i$ be as large as possible.
\item Suppose $j = m$, so $⟦M^a⟧ = \mathcal{N}^b_m \mid \mathcal{N}^1_i$.\\
  By \Cref{theorem:parallelism}, $⟦M^a⟧$ can step (because $\mathcal{N}^1_i$ can step)
  so by \Cref{theorem:values-cor}, $M^a \step M^{a+1}$.
  We can repeat our steps from our choice of
  $\mathcal{N}^a_i \netstep{}{∅}^{\ast} \mathcal{N}^a_m = ⟦M^a⟧$,
  but using $M^{a+1}$ instead of $M^a$.
        Since \HLSCentral doesn't have recursion, eventually we'll arrive at a $M^{a++}$
  that can't step, and then-or-sooner we'll be in the first case above.
  Q.E.D.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of The Completeness Theorem}\label{sec:completeness-proof}
\Cref{theorem:completeness} says that
if $Θ;∅ ⊢ M : T$ and $M \step M'$,
then $⟦M⟧ \netstep{}{∅}^{\ast} ⟦M'⟧$.
We'll need a few lemmas first.

\begin{lemma}[Cruft]\label{theorem:cruft}
  If $Θ;∅ ⊢ M : T$ and $p \not\in Θ$,
  then $⟦M⟧_p = ⊥$.
\end{lemma}
\subsection{Proof of \Cref{theorem:cruft}}
By induction on the typing of $M$:
\begin{itemize}
\item \textsc{TLambda}:
  $\nonempty{p} \subseteq Θ$, therefore $p \not\in \nonempty{p}$,
  therefore $⟦M⟧_p = ⊥$.
\item \textsc{TVar}: Can't happen because $M$ types with empty $Γ$.
\item \textsc{TUnit}, \textsc{TCom}, \textsc{TProj1}, \textsc{TProj2},
  and \textsc{TProjN}:
  Same as \textsc{TLambda}.
\item \textsc{TPair}, \textsc{TVec}, \textsc{TInl}, and \textsc{TInr}:
  In each of these cases we have some number of recursive typing judgments
  to which we can apply the inductive hypothesis.
  This enables the respective cases of the definition of floor
  (as used in the respective cases of the definition of projection)
  to map to $⊥$.
\item \textsc{TApp}: $M = N_1 N_2$.
  By induction, $⟦N_1⟧_p = ⊥$ and $⟦N_2⟧_p = ⊥$,
  so $⟦M⟧_p = ⊥$
\item \textsc{TCase}: Similar to \textsc{TLambda},
  by induction the guard projects to $⊥$ and therefore the whole thing does too.
\end{itemize}

\begin{lemma}[Existence]\label{theorem:existence}
  If $Θ;Γ ⊢ V : d@\nonempty{p}$ and $p,q \in \nonempty{p}$,
  then $⟦V⟧_p = ⟦V⟧_q \neq ⊥$.
\end{lemma}
\subsection{Proof of \Cref{theorem:existence}}
By induction on possible typings of $V$:
\begin{itemize}
\item \textsc{TVar}: Projection is a no-op on variables.
\item \textsc{TUnit}: $⟦V⟧_p = ⟦V⟧_q = ()$.
\item \textsc{TPair}: $p,q \in \nonempty{p_1} ∩ \nonempty{p_2}$,
  so both are in each of them, so we can recurse on $V_1$ and $V_2$.
\item \textsc{TInl} and \textsc{TInr}: simple induction.
\end{itemize}

\begin{lemma}[Bottom]\label{theorem:bottom}
  If $Θ;∅ ⊢ M : T$ and $⟦M⟧_p = ⊥$ and $M \step M'$
  then $⟦M'⟧_p = ⊥$.
\end{lemma}
\subsection{Proof of \Cref{theorem:bottom}}
By induction on the step $M \step M'$.
\begin{itemize}
\item \textsc{AppAbs}: $M = (λ x:T_x \DOT N)@\nonempty{p} V$,
  and necessarily $⟦(λ x:T_x \DOT N)@\nonempty{p}⟧_p = ⊥$.
  Since the lambda doesn't project to a lambda, $p\not\in\nonempty{p}$.
  $M' = N[x:=V\mask\nonempty{p}]$.
        By \textsc{TLambda}, \Cref{theorem:substitution}, and \Cref{theorem:cruft},
  $⟦N[x:=V\mask\nonempty{p}]⟧_p = ⊥$.
\item \textsc{App1}: $M = V N$
  and necessarily $⟦V⟧_p = ⟦N⟧_p = ⊥$.
  By induction on $N \step N'$, $⟦N'⟧_p = ⊥$.
\item \textsc{App2}: Same as \textsc{App1}.
\item \textsc{Case}: The guard must project to $⊥$, so this follows from induction.
\item \textsc{CaseL} (and \textsc{CaseR} by mirror image):
  $M = \CASE{\nonempty{p}}{\INL V}{x_l}{M_l}{x_r}{M_r}$
  and $M' = M_l[x_l := V\mask\nonempty{p}]$.
  Necessarily, $⟦V⟧_p = ⊥$.
  By \textsc{TCase} and \textsc{MTData}, $\INL V$ types as data,
        so by \Cref{theorem:existence} $p \not\in \nonempty{p}$.
        By \textsc{TCase}, \Cref{theorem:substitution}, and \Cref{theorem:cruft},
  $⟦M'⟧_p = ⟦M_l[x_l := V\mask\nonempty{p}]⟧_p = ⊥$.
\item \textsc{Proj1}: $M = \FST{\nonempty{p}}(\PAIR V_1 V_2)$,
  and $p \not \in \nonempty{p}$.
  $M' = V_1 \mask \nonempty{p}$.
  Since $Θ;∅ ⊢ V_1 : T'$ (by \textsc{TPair})
  and $T' \mask \nonempty{p} = T''$ is defined
  (by \textsc{TApp} and the indifference of \textsc{MTData} to the data's structure),
        by \Cref{theorem:enclave} $\nonempty{p};∅ ⊢ V_1 \mask \nonempty{p} : T''$.
        By \Cref{theorem:cruft} this projects to $⊥$.
\item \textsc{Proj2}, \textsc{ProjN}, and \textsc{Com1} are each pretty similar to
  \textsc{Proj1}.
\item \textsc{Com1}, \textsc{ComPair}, \textsc{ComInl}, and \textsc{ComInr}:
    For $M$ to project to ⊥, $p$ must be neither a sender nor a recipient.
    By induction among these cases (with \textsc{Com1} as the base case),
        $M'$ will be some structure of $()@\nonempty{r}$;
        since $p\not\in\nonempty{r}$ and projection uses floor,
        this will project to ⊥.
\end{itemize}

\begin{lemma}[Masked]\label{theorem:masked}
  If $p \in \nonempty{p}$ and $V' = V \mask \nonempty{p}$
  then $⟦V⟧_p = ⟦V'⟧_p$.
\end{lemma}
\subsection{Proof of \Cref{theorem:masked}}
By (inductive) case analysis of endpoint projection:
\begin{itemize}
\item $⟦x⟧_p = x$. By \textsc{MVVar} the mask does nothing.
\item $⟦(λ x:T \DOT M)@\nonempty{q}⟧_p$:
  Since $V \mask \nonempty{p}$ is defined, by \textsc{MVLambda} it does nothing.
\item $⟦()@\nonempty{q}⟧_p$: By \textsc{MVUnit} $V' = ()@(\nonempty{p} ∩ \nonempty{q})$.
  $p$ is in that intersection iff $p \in \nonempty{q}$,
  so the projections will both be $()$ or $⊥$ correctly.
\item $\INL V_l$, $\INR V_r$, $\PAIR V_1 V_2$, $(V_1, \dots, V_n)$: simple recursion.
\item $\FST{\nonempty{q}}$, $\SND{\nonempty{q}}$,
  $\LOOKUP{i}{\nonempty{q}}$, $\COMM{q}{\nonempty{q}}$:
  Since the masking is defined, it does nothing.
\end{itemize}

\begin{lemma}[Floor Zero]\label{theorem:floor-zero}
  $⟦M⟧_p = \FLR{⟦M⟧_p}$
\end{lemma}
\subsection{Proof of \Cref{theorem:floor-zero}}
There are thirteen forms.
Six of them (application, case, injection-r/l, pair and vector)
apply floor directly in the definition of projection.
Six of them (variable, unit, the three lookups, and $\langword{com}$)
can only project to values such that floor is a no-op.
For a lambda $(λ x:T_x \DOT N)@\nonempty{p}$, the proof is by induction on the body $N$.


\begin{lemma}[Distributive Substitution]\label{theorem:distributive-substitution}
  If $Θ;(x : T_x) ⊢ M : T$ and $p \in Θ$, \\
  then $⟦M[x:=V]⟧_p = \FLR{⟦M⟧_p[x := ⟦V⟧_p]}$.
    (Because $⟦V⟧_p$ may be ⊥, this isn't really distribution; an extra flooring operation is necessary.)
\end{lemma}
\subsection{Proof of \Cref{theorem:distributive-substitution}}
It'd be more elegant if substitution really did distribute over projection,
but this weaker statement is what we really need anyway.
The proof is by inductive case analysis on the form of $M$:
\begin{itemize}
\item $\PAIR V_1 V_2$: $⟦M[x:=V]⟧_p = ⟦\PAIR V_1[x:=V] V_2[x:=V]⟧_p$\\
  $= \FLR{\PAIR ⟦V_1[x:=V⟧_p ⟦V_2[x:=V]⟧_p}$ \\
  and $⟦M⟧_p[x := ⟦V⟧_p] = \FLR{\PAIR ⟦V_1⟧_p ⟦V_2⟧_p}[x := ⟦V⟧_p]$.
  \begin{itemize}
  \item Suppose one of $⟦V_1⟧_p$, $⟦V_2⟧_p$ is not $⊥$.
    Then \\
    $⟦M⟧_p[x := ⟦V⟧_p] = (\PAIR \FLR{⟦V_1⟧_p} \FLR{⟦V_2⟧_p})[x := ⟦V⟧_p]$ \\
          which by \Cref{theorem:floor-zero}
    $= (\PAIR ⟦V_1⟧_p ⟦V_2⟧_p)[x := ⟦V⟧_p]$ \\
    $= \PAIR (⟦V_1⟧_p[x := ⟦V⟧_p]) (⟦V_2⟧_p[x := ⟦V⟧_p])$. \\
    Thus $\FLR{⟦M⟧_p[x := ⟦V⟧_p]}
     = \FLR{\PAIR (⟦V_1⟧_p[x := ⟦V⟧_p]) (⟦V_2⟧_p[x := ⟦V⟧_p])}$. \\
    By induction,
    $⟦V_1[x:=V]⟧_p = \FLR{⟦V_1⟧_p[x := ⟦V⟧_p]}$ \\
          and
    $⟦V_2[x:=V]⟧_p = \FLR{⟦V_2⟧_p[x := ⟦V⟧_p]}$;
    with that in mind,
    \begin{itemize}
    \item Suppose one of $⟦V_1[x:=V]⟧_p$, $⟦V_1[x:=V]⟧_p$ is not $⊥$. \\
      $\FLR{⟦M⟧_p[x := ⟦V⟧_p]}
       = \PAIR \FLR{⟦V_1⟧_p[x := ⟦V⟧_p]} \FLR{⟦V_2⟧_p[x := ⟦V⟧_p]}$, \\
      and $⟦M[x:=V]⟧_p = \PAIR \FLR{⟦V_1[x:=V⟧_p} \FLR{⟦V_2[x:=V]⟧_p}$ \\
       $= \PAIR ⟦V_1[x:=V⟧_p ⟦V_2[x:=V]⟧_p$
      Q.E.D.
    \item Otherwise, $\FLR{⟦M⟧_p[x := ⟦V⟧_p]} = ⊥ = ⟦M[x:=V]⟧_p$.
    \end{itemize}
  \item Otherwise, $⟦M⟧_p[x := ⟦V⟧_p] = \FLR{\PAIR ⊥ ⊥}[x := ⟦V⟧_p] = ⊥$. \\
      Note that, by induction \textit{etc},
    $⟦V_1⟧_p = ⊥ = ⟦V_1⟧_p[x := ⟦V⟧_p] = \FLR{⟦V_1⟧_p[x := ⟦V⟧_p]}
     = ⟦V_1[x:=V]⟧_p$,
    and the same for $V_2$, so
    $⟦M[x:=V]⟧_p = ⊥$, Q.E.D.
  \end{itemize}
\item $\INL V_l$, $\INR V_r$, $(V_1, \dots, V_n)$:
  Follow the same inductive pattern as $\PAIR$.
\item $N_1 N_2$:
  $⟦M[x:=V]⟧_p = ⟦N_1[x:=V] N_2[x:=V]⟧_p = \FLR{⟦N_1[x:=V]⟧_p ⟦N_2[x:=V]⟧_p}$ \\
  $= \begin{cases}
    \FLR{⟦N_1[x:=V]⟧_p} = ⊥, \FLR{⟦N_2[x:=V]⟧_p} = L :& ⊥ \\
    \text{else} :& \FLR{⟦N_1[x:=V]⟧_p} \FLR{⟦N_2[x:=V]⟧_p}
  \end{cases}$ \\
  $= \begin{cases}
    ⟦N_1[x:=V]⟧_p = ⊥, ⟦N_2[x:=V]⟧_p = L :& ⊥ \\
    \text{else} :& ⟦N_1[x:=V]⟧_p ⟦N_2[x:=V]⟧_p
  \end{cases}$ \\
  and $\FLR{⟦M⟧_p[x:=⟦V⟧_p]} = \FLR{\FLR{⟦N_1⟧_p ⟦N_2⟧_p}[x:=⟦V⟧_p]}$ \\
  $= \begin{cases}
    \FLR{⟦N_1⟧_p} = ⊥, \FLR{⟦N_2⟧_p} = L :& \FLR{⊥[x:=⟦V⟧_p]} = ⊥ \\
    \text{else} :& \FLR{ (\FLR{⟦N_1⟧_p} \FLR{⟦N_2⟧_p})[x:=⟦V⟧_p] } \\
                 & \quad= \FLR{ (⟦N_1⟧_p[x:=⟦V⟧_p]) (⟦N_2⟧_p[x:=⟦V⟧_p]) }
  \end{cases}$ \\
  $= \begin{cases}
    \FLR{⟦N_1⟧_p[x:=⟦V⟧_p]} = ⊥, \FLR{⟦N_2⟧_p[x:=⟦V⟧_p]} = L : ⊥ \\
    \text{else} : \FLR{⟦N_1⟧_p[x:=⟦V⟧_p]} \FLR{⟦N_2⟧_p[x:=⟦V⟧_p]}
  \end{cases}$ \\
  (Note that we collapsed the $\FLR{⟦N_1⟧_p} = ⊥,\dots$ case.
  We can do that because if $⟦N_1⟧_p = ⊥$ then so does $\FLR{⟦N_1⟧_p[x:=⟦V⟧_p]}$
  and if $⟦N_2⟧_p = L$ then $\FLR{⟦N_2⟧_p[x:=⟦V⟧_p]}$ is also a value.) \\
  By induction, $⟦N_1[x:=V]⟧_p = \FLR{⟦N_1⟧_p[x := ⟦V⟧_p]}$ \\
  and $⟦N_2[x:=V]⟧_p = \FLR{⟦N_2⟧_p[x := ⟦V⟧_p]}$.
\item $y$: trivial because EPP and floor are both no-ops.
\item $(λ y:T_y \DOT N)@\nonempty{p}$:
  \begin{itemize}
  \item If $p \not\in \nonempty{p}$, both sides of the equality are $⊥$.
  \item If $V' = V \mask \nonempty{p}$ is defined, then \\
    $⟦(λ y:T_y \DOT N)@\nonempty{p}[x:=V]⟧_p
    =⟦(λ y:T_y \DOT N[x:=V'])@\nonempty{p}⟧_p
    =  λ y \DOT ⟦N[x:=V']⟧_p$ \\
    and
    $\FLR{⟦(λ y:T_y \DOT N)@\nonempty{p}⟧_p[x := ⟦V⟧_p]}$ \\
    $= \FLR{(λ y \DOT ⟦N⟧_p)[x := ⟦V⟧_p]  }$ \\
    $= \FLR{ λ y \DOT (⟦N⟧_p[x := ⟦V⟧_p]) }$ \\
          $= \FLR{ λ y \DOT (⟦N⟧_p[x := ⟦V'⟧_p])}$ (by \Cref{theorem:masked}) \\
    $=  λ y \DOT \FLR{(⟦N⟧_p[x := ⟦V'⟧_p])}$ \\
    Then we do induction on $N$ and $V'$.
  \item Otherwise, substitution in the central program is a no-op.  
    \begin{itemize}
    \item $⟦(λ y:T_y \DOT N)@\nonempty{p}[x:=V]⟧_p = ⟦(λ y:T_y \DOT N)@\nonempty{p}⟧_p
      = λ y \DOT ⟦N⟧_p$ \\
      and \\ $\FLR{⟦(λ y:T_y \DOT N)@\nonempty{p}⟧_p[x := ⟦V⟧_p]}
      = \FLR{(λ y \DOT ⟦N⟧_p)[x := ⟦V⟧_p]} \\
      = \FLR{λ y \DOT (⟦N⟧_p[x := ⟦V⟧_p])}$ \\
      $= λ y \DOT \FLR{⟦N⟧_p[x := ⟦V⟧_p]}$.
    \item Since we already known
      $(λ y:T_y \DOT N)@\nonempty{p}[x:=V] = (λ y:T_y \DOT N)@\nonempty{p}$,
            we can apply \Cref{theorem:substitution} to $M$ and unpack the typing of
      $M[x:=V] = M$
      to get $\nonempty{p};(y:T_y) ⊢ N : T'$.
  \item By \Cref{theorem:unused}, we get $N[x:=V] = N$.
    \item By induction on $N$ and $V$, we get
      $\FLR{⟦N⟧_p[x := ⟦V⟧_p]} = ⟦N[x:=V]⟧_p =  ⟦N⟧_p$,
      QED.
    \end{itemize}
  \end{itemize}
\item $\CASE{\nonempty{p}}{N}{x_l}{N_l}{x_r}{N_r}$: % (maybe I should work these out more?)
  \begin{itemize}
  \item If $⟦N⟧_p = ⊥$ then $\FLR{⟦N⟧_p[x:=⟦V⟧_p]} = ⊥ = ⟦N[x:=V]⟧_p$ (by induction),
    so both halfs of the equality are $⊥$.
  \item Else if $p \not \in \nonempty{p}$, then we get \\
    $⟦\CASE{\nonempty{p}}{N[x:=V]}{x_l}{N_l'}{x_r}{N_r'}⟧_p
    = \CASE{\nonempty{p}}{⟦N[x:=V]⟧_p}{x_l}{⊥}{x_r}{⊥}$ \\
    and \\
    $\FLR{⟦\CASE{\nonempty{p}}{N}{x_l}{N_l}{x_r}{N_r}⟧_p[x := ⟦V⟧_p]} \\
    = \FLR{(\CASE{\nonempty{p}}{⟦N⟧_p}{x_l}{⊥}{x_r}{⊥})[x := ⟦V⟧_p]} \\
    = \FLR{\CASE{\nonempty{p}}{⟦N⟧_p[x := ⟦V⟧_p]}{x_l}{⊥}{x_r}{⊥}}$. \\
    Since we've assumed $\FLR{⟦N⟧_p[x:=⟦V⟧_p]} \neq ⊥$,
    these are equal by induction.
  \item Else if $V' = V \mask \nonempty{p}$ is defined then we can do induction similar
    similar to how we did for the respective lambda case, except the induction is
    three-way.
  \item Otherwise, it's similar to the respective lambda case, just more verbose.
  \end{itemize}
\item $()@\nonempty{p}$, $\FST{\nonempty{p}}$, $\SND{\nonempty{p}}$,
  $\LOOKUP{i}{\nonempty{p}}$, and $\COMM{s}{\nonempty{r}}$:
  trivial because substitution and floor are no-ops.
\end{itemize}

\begin{lemma}[Weak Completeness]\label{theorem:weak-completeness}
  If $Θ;∅ ⊢ M : T$ and $M \step M'$
  then $⟦M⟧_p \prcstep{μ}{η}^{?} ⟦M'⟧_p$.  
  (\ie it takes zero or one steps to get there.)
\end{lemma}
\subsection{Proof of \Cref{theorem:weak-completeness}}
If $⟦M⟧_p = ⊥$ then this is follows trivially from \Cref{theorem:bottom},
so assume it doesn't.
We proceed with induction on the form of $M \step M'$:
\begin{itemize}
\item \textsc{AppAbs}: $M = (λ x:T_x \DOT N)@\nonempty{p} V$,
  and $M' = N[x:=V\mask\nonempty{p}]$.
  By assumption, the lambda doesn't project to $⊥$, so $p \in \nonempty{p}$
  and $⟦M⟧_p \prcstep{∅}{∅} \FLR{⟦N⟧_p[x:=⟦V⟧_p]}$ by \textsc{LAbsApp}. \\
        By \Cref{theorem:masked} and \Cref{theorem:distributive-substitution}
  $\FLR{⟦N⟧_p[x:=⟦V⟧_p]} = \FLR{⟦N⟧_p[x:=⟦V\mask\nonempty{p}⟧_p]}
  = ⟦N[x:=V\mask\nonempty{p}]⟧_p = ⟦M'⟧_p$.
\item \textsc{App1}: $M = V N \step V N' = M'$.
  By induction, $⟦N⟧_p \prcstep{μ}{η}^{?} ⟦N'⟧_p$.
  \begin{itemize}
  \item Assume $⟦V⟧_p = ⊥$.
    By our earlier assumption, $⟦N⟧_p \neq ⊥$.
    Since $⟦N⟧_p$ can step; that step justifies a \textsc{LApp1} step
    with the same annotations.
          If $⟦N'⟧_p$ is a value then
    that'll be handled by the floor built into \textsc{LApp1}.
  \item Otherwise, the induction is even simpler,
    we just don't have to worry about possibly collapsing the whole thing to $⊥$.
  \end{itemize}
\item \textsc{App2}:
  $M = N_1 N_2 \step N_1' N_2 = M'$.
  By induction, $⟦N_1⟧_p \prcstep{μ}{η}^{?} ⟦N_1'⟧_p$.
  \begin{itemize}
  \item Assume $⟦N_2⟧_p = L$.
    By our earlier assumption, $⟦N_1⟧_p \neq ⊥$.
    Since $⟦N_1⟧_p$ steps, that step justifies a \textsc{LApp2} step
    with the same annotations.
         If $⟦N_1'⟧_p$ is a value then
    that'll be handled by the floor built into \textsc{LApp2}.
  \item Otherwise, the induction is even simpler.
  \end{itemize}
\item \textsc{Case}: By our assumptions, the guard can't project to $⊥$;
  we just do induction on the guard to satisfy \textsc{LCase}.
\item \textsc{CaseL} (\textsc{CaseR} mirrors):
  $M = \CASE{\nonempty{p}}{\INL V}{x_l}{M_l}{x_r}{M_r}$,
  and $⟦M⟧_p = \CASE{}{\INL ⟦V⟧_p}{x_l}{B_l}{x_r}{B_r}$.
  $⟦M⟧_p \prcstep{∅}{∅} \FLR{B_l[x_l := ⟦V⟧_p]}$ by \textsc{LCaseL}.
  $M' = M_l[x_l := V\mask\nonempty{p}]$.
  If $p \in \nonempty{p}$
  then $B_l = ⟦M_l⟧_p$
        and by \Cref{theorem:masked} and \Cref{theorem:distributive-substitution}
  $\FLR{B_l[x_l := ⟦V⟧_p]} = \FLR{⟦M_l⟧_p[x_l := ⟦V⟧_p]}
  = \FLR{⟦M_l⟧_p[x_l := ⟦V\mask\nonempty{p}⟧_p]}$ \\
  $= ⟦M_l[x_l := V\mask\nonempty{p}]⟧_p
  = ⟦M'⟧_p$. \\
  Otherwise, $B_l[x_l := ⟦V⟧_p] = ⊥$
        and by \textsc{TCase}, \Cref{theorem:substitution}, and \Cref{theorem:cruft},
  $⟦M'⟧_p = ⊥$.
\item \textsc{Proj1}: $M = \FST{\nonempty{p}} (\PAIR V_1 V_2)$
  and $M' = V_1 \mask \nonempty{p}$.
  Since we assumed $⟦M⟧_p \neq ⊥$, $p \in \nonempty{p}$. \\
  $⟦M⟧_p = \FST{} \FLR{\PAIR ⟦V_1⟧_p ⟦V_2⟧_p} = \FST{} (\PAIR ⟦V_1⟧_p ⟦V_2⟧_p)$
        by \Cref{theorem:existence} and \textsc{TPair}.
  This steps by \textsc{LProj1} to $⟦V_1⟧_p$,
        which equals $⟦M'⟧_p$ by \Cref{theorem:masked}.
\item \textsc{Proj2}, \textsc{ProjN}: Same as \textsc{Proj1}.
\item \textsc{Com1}: $M = \COMM{s}{\nonempty{r}} ()@\nonempty{p}$
  and $M' = ()@\nonempty{r}$.
  \begin{itemize}
  \item $s = p$ and $p \in \nonempty{r}$:
    By \textsc{MVUnit}, $p \in \nonempty{p}$,
    so $⟦M⟧_p = \SEND{\nonempty{r} ∖ \set{p}}^{\ast} ()$,
    which steps by \textsc{LSendSelf} (using \textsc{LSend1}) to $()$.
    $⟦M'⟧_p = ()$.
  \item $s = p$ and $p \not\in \nonempty{r}$:
    By \textsc{MVUnit}, $p \in \nonempty{p}$,
    so $⟦M⟧_p = \SEND{\nonempty{r}} ()$,
    which steps by \textsc{LSend1} to $⊥$.
    $⟦M'⟧_p = ⊥$.
  \item $s \neq p$ and $p \in \nonempty{r}$:
    $⟦M⟧_p = \RECV{s} ⟦()@\nonempty{p}⟧_p$,
    which can step
    (arbitrarily, but with respective annotation)
    by \textsc{LRecv} to $⟦M'⟧_p$.
  \item Otherwise, we violate our earlier assumption.
  \end{itemize}
\item \textsc{ComPair}, \textsc{ComInl}, and \textsc{ComInr}:
  Each uses the same structure of proof as \text{Com1},
  using induction between the cases
  to support the respective process-semantics step.
\end{itemize}

\subsection{\Cref{theorem:completeness}}
\Cref{theorem:completeness} says that
  if $Θ;∅ ⊢ M : T$ and $M \step M'$,
  then $⟦M⟧ \netstep{}{∅}^{\ast} ⟦M'⟧$.

The proof is by case analysis on the semantic step $M \step M'$:
\begin{itemize}
\item \textsc{AppAbs},
  \textsc{CaseL},
  \textsc{CaseR},
  \textsc{Proj1},
  \textsc{Proj2},
  and \textsc{ProjN}:
  Necessarily, the set of parties $\nonempty{p}$ for whom
  $⟦M⟧_{p\in\nonempty{p}} \neq ⊥$ is not empty.
  For every $p \in \nonempty{p}$,
        by \Cref{theorem:weak-completeness} $⟦M⟧_p \prcstep{∅}{∅}^{?} ⟦M'⟧_p$
  (checking the cases to see that the annotations are really empty!).
  By \textsc{NPro}, each of those is also a
  network step,
        which by \Cref{theorem:parallelism} can be composed in any order to get
  $⟦M⟧ \netstep{}{∅}^{\ast} \mathcal{N}$.
  For every $p \in \nonempty{p}$,
  $\mathcal{N}(p) = ⟦M'⟧_p$,
        and (by \Cref{theorem:bottom}) for every $q \not\in \nonempty{p}$,
  $\mathcal{N}(q) = ⊥ = ⟦M'⟧_q$,
  Q.E.D.
\item \textsc{Com1},
  \textsc{ComPair},
  \textsc{ComInl},
  and \textsc{ComInr}:
  $M = \COMM{s}{\nonempty{r}} V$.
  By the recursive structure of \textsc{Com1}, \textsc{ComPair}, \textsc{ComInl},
  and \textsc{ComInr}, $M'$ is some structure of
  $\set{\PAIR, \INL{}, \INR{}, ()@\nonempty{r}}$,
  and $⟦M'⟧_{r\in\nonempty{r}} = ⟦V⟧_s$.
  For every $q \not\in \nonempty{r} ∪ \set{s}$, $⟦M⟧_q = ⊥ = ⟦M'⟧_q$
        by \Cref{theorem:bottom}.
  Consider two cases:
  \begin{itemize}
  \item $s \not\in \nonempty{r}$: \\
      By \Cref{theorem:weak-completeness}
    $⟦M⟧_s = \SEND{\nonempty{r}} ⟦V⟧_s
    \prcstep{\set{(r, ⟦V⟧_s) \mid r \in \nonempty{r}}}{∅} ⊥$.\\
    By the previously mentioned structure of $M'$, $⟦M'⟧_s = ⊥$. \\
    For every $r \in \nonempty{r}$,
    by \Cref{theorem:weak-completeness}
    $⟦M⟧_r = \RECV{s} ⟦V⟧_r
    \prcstep{∅}{\set{(s,⟦V⟧_s)}} ⟦V⟧_s = ⟦M'⟧_{r}$. \\
    By \textsc{NPro},
    $s[⟦M⟧_s] \netstep{s}{\set{(r, ⟦V⟧_s) \mid r \in \nonempty{r}}} s[⊥=⟦M'⟧_s]$.\\
    This composes in parallel with each of the $r_{\in\nonempty{r}}[⟦M⟧_r]$
    by \textsc{NCom} in any order until the unmactched send is empty.
    Everyone in and not-in $\nonempty{r} ∪ \set{s}$ has stepped, if needed,
    to the respective projection of $M'$.
  \item $s \in \nonempty{r}$: Let $\nonempty{r_0} = \nonempty{r} ∖ \set{s}$. \\
    By \Cref{theorem:weak-completeness}
    $⟦M⟧_s = \SEND{\nonempty{r_0}}^{\ast} ⟦V⟧_s
    \prcstep{\set{(r, ⟦V⟧_s) \mid r \in \nonempty{r_0}}}{∅} ⟦V⟧_s
    = ⟦M'⟧_{s\in \nonempty{r}}$. \\
    For every $r \in \nonempty{r_0}$,
    by \Cref{theorem:weak-completeness}
    $⟦M⟧_r = \RECV{s} ⟦V⟧_r
    \prcstep{∅}{\set{(s,⟦V⟧_s)}} ⟦V⟧_s = ⟦M'⟧_{r}$. \\
    We proceed as in the previous case.
  \end{itemize}
\item \textsc{App1} (\textsc{App2} and \textsc{Case} are similar):
  $M = V N$.
  By induction, $⟦N⟧ \netstep{}{∅}^{\ast} ⟦N'⟧$.
  Every $N$ step in that process in which a single party advances by \textsc{NPro}
  can justify a corresponding $M$ step by \textsc{LApp1}.
  \textsc{NCom} steps are basically the same: each of the participating parties will
  justify a \textsc{LApp1} $M$ step with a $N$ step;
  since this doesn't change the send \& receive annotations,
  the cancellation will still work.
\end{itemize}
